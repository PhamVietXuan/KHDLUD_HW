{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Họ tên: Phạm Viết Xuân\n",
        "\n",
        "MSSV: 18120658"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW3: Các loại bộ nhớ trong CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "Với các GPU tương đối mới thì để biên dịch chỉ cần dùng câu lệnh: \\\n",
        "`nvcc tên-file.cu -o tên-file-chạy`\n",
        "\n",
        "Nhưng trên Colab mình thường lấy được GPU khá cũ là Tesla K80 với compute capability (phiên bản phần cứng) là 3.7; để biên dịch đúng với GPU khá cũ này thì bạn cần dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_37 tên-file.cu -o tên-file-chạy` \\\n",
        "Trong đó, 37 chính là compute capability của GPU Tesla K80.\n",
        "\n",
        "Để phòng trường hợp khi làm bài bạn lấy được GPU có compute capability x.x nhưng khi chấm bài Thầy lại lấy được GPU có compute capability khác x.x, dưới đây mình sẽ có đoạn code Python để tự động lấy 2 con số ứng với compute capability của GPU và lưu vào 2 biến `major` và `minor`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCkmnirl2xWF",
        "outputId": "c485e38b-ac73-4a65-d12a-03beb110c27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU compute capability: 3.7\n"
          ]
        }
      ],
      "source": [
        "from numba import cuda\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f'GPU compute capability: {major}.{minor}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1-pmi72yS6"
      },
      "source": [
        "Một khi đã chạy đoạn code Python ở trên, để biên dịch thì bạn sẽ dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_{major}{minor} tên-file.cu -o tên-file-chạy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCyT0o8Z7nj"
      },
      "source": [
        "Dưới đây, khi làm bài thì bạn có thể tùy ý thêm/xóa cell. Đừng xóa mấy cell có chữ của Thầy là được."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbFLx1i4JxIE",
        "outputId": "e5ede88d-7ac9-4317-99f4-88e43dfb51be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "HW3.cu(112): warning: variable \"filterValue\" was declared but never referenced\n",
            "\n",
            "HW3.cu(127): warning: variable \"i\" was declared but never referenced\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_37 HW3.cu -o HW3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZNqZuECjNso",
        "outputId": "48fbbd27-0626-4132-eb2e-cf1164fca94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla K80\n",
            "Compute capability: 3.7\n",
            "Num SMs: 13\n",
            "Max num threads per SM: 2048\n",
            "Max num warps per SM: 64\n",
            "GMEM: 11996954624 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 1572864 bytes\n",
            "SMEM / one SM: 114688 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 32x32, grid size 16x16\n",
            "Kernel time: 18.983969 ms\n",
            "Error: 0.000230\n",
            "\n",
            "Kernel 2, block size 32x32, grid size 16x16\n",
            "Kernel time: 1.124640 ms\n",
            "Error: 0.000230\n",
            "\n",
            "Kernel 3, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.874752 ms\n",
            "Error: 0.000230\n"
          ]
        }
      ],
      "source": [
        "!./HW3 in.pnm out.pnm "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XebMjR45-0Io"
      },
      "source": [
        "- Dùng SMEM nhanh hơn với dùng GMEM vì: Trước khi thực hiện thì data đã được copy vào SMEM và sử dụng lại nhiều lần trong quá trình tính toán tích chập. Mà tốc độ đọc/ghi của SMEM nhanh hơn so với GMEM nên tốc độ được cải thiện nhiều.\n",
        "- Sử dụng CMEM nhanh hơn khi không dùng bởi vì dc_filter được lưu trữ ở const cache nên việc đọc/ghi được thực hiện nhanh hơn nhiều so với việc truy cập từ DRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HGdo1vz5arUX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "HW3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}